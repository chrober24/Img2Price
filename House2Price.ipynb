{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "House2Price.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "mount_file_id": "1zJAmMBU0FY-3S_cHNdl9MvatXrBxkaN7",
      "authorship_tag": "ABX9TyMzae7E7tENUaQMkjKQETEM",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chrober24/Img2Price/blob/main/House2Price.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fLCxGPlexXsB",
        "outputId": "0a750bfe-e57e-44dd-82f6-8609fa39cf2d"
      },
      "source": [
        "import os\n",
        "from PIL import Image  # or you can use the keras one to load images\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import glob\n",
        "import cv2\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "\n",
        "def load_dataset(top_dir=\"/content/drive/MyDrive/Image_Classification/houses/\"):\n",
        "    images_dataset = []\n",
        "    for root, dirs, files in os.walk(top_dir):\n",
        "        for name in files:\n",
        "            # print(os.path.join(root, name))\n",
        "            img = np.array(Image.open(os.path.join(root, name)))\n",
        "            img = img.astype('float32')            \n",
        "            img /= 255\n",
        "\n",
        "            images_dataset.append(img)\n",
        "    return np.array(images_dataset)\n",
        "img_data = load_dataset()\n",
        "img_data[1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:15: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  from ipykernel import kernelapp as app\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[0.01568628, 0.5176471 , 0.8117647 ],\n",
              "        [0.01960784, 0.52156866, 0.8156863 ],\n",
              "        [0.02352941, 0.5254902 , 0.81960785],\n",
              "        ...,\n",
              "        [0.36078432, 0.4       , 0.30588236],\n",
              "        [0.18039216, 0.23137255, 0.12156863],\n",
              "        [0.03137255, 0.08235294, 0.        ]],\n",
              "\n",
              "       [[0.01568628, 0.5176471 , 0.8117647 ],\n",
              "        [0.01960784, 0.52156866, 0.8156863 ],\n",
              "        [0.02352941, 0.5254902 , 0.81960785],\n",
              "        ...,\n",
              "        [0.07450981, 0.11372549, 0.01960784],\n",
              "        [0.11764706, 0.16862746, 0.06666667],\n",
              "        [0.14509805, 0.19607843, 0.08627451]],\n",
              "\n",
              "       [[0.01960784, 0.52156866, 0.8156863 ],\n",
              "        [0.02352941, 0.5254902 , 0.81960785],\n",
              "        [0.02745098, 0.5294118 , 0.8235294 ],\n",
              "        ...,\n",
              "        [0.06666667, 0.10196079, 0.01960784],\n",
              "        [0.06666667, 0.11372549, 0.01960784],\n",
              "        [0.01568628, 0.0627451 , 0.        ]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[0.6431373 , 0.6156863 , 0.5529412 ],\n",
              "        [0.6431373 , 0.6156863 , 0.5529412 ],\n",
              "        [0.6313726 , 0.6039216 , 0.5411765 ],\n",
              "        ...,\n",
              "        [0.74509805, 0.7607843 , 0.8039216 ],\n",
              "        [0.68235296, 0.7607843 , 0.7647059 ],\n",
              "        [0.6627451 , 0.7882353 , 0.76862746]],\n",
              "\n",
              "       [[0.6509804 , 0.627451  , 0.57254905],\n",
              "        [0.6431373 , 0.61960787, 0.5647059 ],\n",
              "        [0.6392157 , 0.6156863 , 0.56078434],\n",
              "        ...,\n",
              "        [0.6901961 , 0.76862746, 0.77254903],\n",
              "        [0.6392157 , 0.76862746, 0.73333335],\n",
              "        [0.654902  , 0.81960785, 0.7647059 ]],\n",
              "\n",
              "       [[0.61960787, 0.59607846, 0.5411765 ],\n",
              "        [0.60784316, 0.58431375, 0.5294118 ],\n",
              "        [0.61960787, 0.59607846, 0.5411765 ],\n",
              "        ...,\n",
              "        [0.7137255 , 0.827451  , 0.8117647 ],\n",
              "        [0.70980394, 0.87058824, 0.8156863 ],\n",
              "        [0.6627451 , 0.84705883, 0.76862746]]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3X52BAKy8H86",
        "outputId": "e9a7c7ed-218a-4b22-d8d3-683032bd3889"
      },
      "source": [
        "inputPath = \"/content/drive/MyDrive/Image_Classification/houses/\"\n",
        "IMG_HEIGHT = 224\n",
        "IMG_WIDTH = 224\n",
        "\n",
        "def create_dataset(img_folder=inputPath):\n",
        "   \n",
        "    img_data_array=[]\n",
        "\n",
        "    for file in os.listdir(img_folder):\n",
        "       \n",
        "        image_path= os.path.join(img_folder, file)\n",
        "        image= cv2.imread( image_path, cv2.COLOR_BGR2RGB)\n",
        "        image=cv2.resize(image, (IMG_HEIGHT, IMG_WIDTH),interpolation = cv2.INTER_AREA)\n",
        "        image=np.array(image)\n",
        "        image = image.astype('float32')\n",
        "        image /= 255 \n",
        "        img_data_array.append(image)\n",
        "    return img_data_array\n",
        "\n",
        "img_data = create_dataset()\n",
        "img_data[0].shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(224, 224, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QwsGdT2G8hxU",
        "outputId": "7d971845-df58-4884-da5f-d6f0b0983378"
      },
      "source": [
        "cols = [\"index\" , \"price\"]\n",
        "inputPath = \"/content/housinginfo.csv\"\n",
        "df = pd.read_csv(inputPath, sep=\",\" , header=None, names=cols)\n",
        "df.head()\n",
        "\n",
        "ID = df[\"index\"]\n",
        "price = df[\"price\"].astype(str).astype(int)\n",
        "price_norm = price / price.max()\n",
        "price_norm\n",
        "\n",
        "\n",
        "X = img_data\n",
        "y = price_norm\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "len(X), len(X_train), len(X_test), len(y), len(y_train), len(y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(600, 480, 120, 600, 480, 120)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "id": "Wz5_AlBY3zqk",
        "outputId": "c702ab40-29e9-4243-f113-fa4341d72e40"
      },
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.model_selection import train_test_split\n",
        "from pyimagesearch import datasets\n",
        "from pyimagesearch import models\n",
        "import numpy as np\n",
        "import argparse\n",
        "import locale\n",
        "import os\n",
        "\n",
        "def create_cnn(width, height, depth, filters=(16, 32, 64), regress=False):\n",
        "\t# initialize the input shape and channel dimension, assuming\n",
        "\t# TensorFlow/channels-last ordering\n",
        "\tinputShape = (height, width, depth)\n",
        "\tchanDim = -1\n",
        "\n",
        "  \t# define the model input\n",
        "\tinputs = Input(shape=inputShape)\n",
        "\t# loop over the number of filters\n",
        "\tfor (i, f) in enumerate(filters):\n",
        "\t\t# if this is the first CONV layer then set the input\n",
        "\t\t# appropriately\n",
        "\t\tif i == 0:\n",
        "\t\t\tx = inputs\n",
        "\t\t# CONV => RELU => BN => POOL\n",
        "\t  x = Conv2D(f, (3, 3), padding=\"same\")(x)\n",
        "\t  x = Activation(\"relu\")(x)\n",
        "\t\tx = BatchNormalization(axis=chanDim)(x)\n",
        "\t\tx = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "  \n",
        "  \t# flatten the volume, then FC => RELU => BN => DROPOUT\n",
        "\t  x = Flatten()(x)\n",
        "  \tx = Dense(16)(x)\n",
        "\t  x = Activation(\"relu\")(x)\n",
        "    x = BatchNormalization(axis=chanDim)(x)\n",
        "\t  x = Dropout(0.5)(x)\n",
        "\t# apply another FC layer, this one to match the number of nodes\n",
        "\t# coming out of the MLP\n",
        "  \tx = Dense(4)(x)\n",
        "\t  x = Activation(\"relu\")(x)\n",
        "\t# check to see if the regression node should be added\n",
        "\t  if regress:\n",
        "\t\t  x = Dense(1, activation=\"linear\")(x)\n",
        "\t# construct the CNN\n",
        "  \t  model = Model(inputs, x)\n",
        "\t# return the CNN\n",
        "\treturn model\n",
        "\n",
        "model = models.create_cnn(224, 224, 3, regress=True)\n",
        "opt = Adam(lr=1e-3, decay=1e-3 / 200)\n",
        "model.compile(loss=\"mean_absolute_percentage_error\", optimizer=opt)\n",
        "# train the model\n",
        "print(\"[INFO] training model...\")\n",
        "model.fit(x=X_train, y=y_train, \n",
        "    validation_data=(X_test, y_test),\n",
        "    epochs=200, batch_size=8)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndentationError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-68-f14f9c454c00>\"\u001b[0;36m, line \u001b[0;32m25\u001b[0m\n\u001b[0;31m    x = Conv2D(f, (3, 3), padding=\"same\")(x)\u001b[0m\n\u001b[0m                                            ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LPCU4s0_C6MP"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}